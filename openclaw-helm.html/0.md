<img src="${ASSETS_DIR}/openclaw-logo-text.png" alt="OpenClaw Logo" style="max-width: 400px; display: block; margin: 0 auto 2em auto;" />

If you've been anywhere near Hacker News in the past few weeks, you've probably seen OpenClaw. The project, originally named Clawdbot, then briefly Moltbot before settling on its current name, has exploded in popularity since late last year. It crossed 100,000 GitHub stars and attracted around 2 million visitors in a single week. The hype got so intense that [Cloudflare's stock jumped 14%](https://www.reuters.com/business/cloudflare-surges-viral-ai-agent-buzz-lifts-expectations-2026-01-27/) because people were using their tunnel services to host the tool.

What makes OpenClaw interesting isn't just that it's another AI assistant. It runs locally, connects to your existing messaging platforms (WhatsApp, Telegram, Signal, Slack, Discord, and more), and actually _does things_ autonomously in a loop. It's less chatbot, more autonomous agent. If you've been following the [Ralph Wiggum technique](https://github.com/ghuntley/how-to-ralph-wiggum), the idea of letting AI iterate continuously until a task is done, OpenClaw is essentially that methodology packaged into something usable. Give it a task, let it run, wake up to results.

I run Kubernetes for everything in my homelab. When I saw OpenClaw gaining traction, I realized there wasn't a Helm chart available for deploying it. So I built one myself, that's just how I operate. Everything in my homelab is declarative, version-controlled in Git, and managed through ArgoCD.

This post walks through deploying OpenClaw on Kubernetes using [my Helm chart](https://github.com/serhanekicii/openclaw-helm) and managing it with ArgoCD.

### Deployment Architecture

The setup is straightforward:

- **OpenClaw** runs as a single-replica Deployment (it cannot scale horizontally by design)
- **Configuration** is stored in a ConfigMap using JSON5 format
- **Persistent storage** keeps workspace data, sessions, and application state
- **Secrets** are managed externally (Vault recommended, but optional)
- **ArgoCD** watches the Git repository and reconciles changes automatically

The Helm chart is built on the [bjw-s app-template](https://github.com/bjw-s/helm-charts).

#### GitOps Behavior

This is important: **any configuration done via the OpenClaw web UI is ephemeral**. When the pod restarts, UI changes are wiped. The source of truth is your Helm values and manifests in Git. This is intentional. If you want persistent configuration changes, commit them to your repository.

### Quick Start: Helm Without ArgoCD

If a declarative GitOps setup isn't your thing, or you just want to test the deployment quickly without setting up a full pipeline, you can install directly with Helm. This works fine for simpler setups or if you prefer managing releases imperatively.

```bash
helm repo add openclaw https://serhanekicii.github.io/openclaw-helm
helm repo update

helm install openclaw openclaw/openclaw -n openclaw --create-namespace -f values.yaml
```

To uninstall:

```bash
helm uninstall openclaw -n openclaw
```

The rest of this post assumes you want the ArgoCD approach, but everything about values, secrets, and networking applies regardless of how you deploy.

### ArgoCD and GitOps Setup

If you're new to ArgoCD, start with their [getting started guide](https://argo-cd.readthedocs.io/en/stable/getting_started/). The basic idea: you define your desired state in a Git repository, and ArgoCD continuously reconciles your cluster to match.

#### Umbrella Charts

For managing applications in a GitOps repository, I use the [umbrella chart pattern](https://helm.sh/docs/howto/charts_tips_and_tricks/). Instead of pointing ArgoCD directly at a remote Helm repository, you create a local chart that wraps the upstream chart as a dependency. This gives you a clean structure where each application lives in its own directory with just two files to manage: `Chart.yaml` and `values.yaml`.

Here's what the directory structure looks like:

```
workloads/
└── my-cluster/
    └── openclaw/
        ├── Chart.yaml
        ├── values.yaml
        └── crds/
            └── vault-secret.yaml
```

The `Chart.yaml` declares the upstream chart as a dependency:

```yaml
apiVersion: v2
name: openclaw
description: OpenClaw deployment for my-cluster
type: application
version: 1.0.0
appVersion: "2026.1.30"

dependencies:
  - name: openclaw
    version: 1.0.0
    repository: https://serhanekicii.github.io/openclaw-helm
```

Then your `values.yaml` contains the overrides, namespaced under the dependency name:

```yaml
openclaw:
  app-template:
    controllers:
      main:
        containers:
          main:
            envFrom:
              - secretRef:
                  name: openclaw-env-secret
    # ... rest of your configuration
```

Run `helm dependency update` to fetch the chart, and you're ready to deploy. This pattern works well with [ApplicationSets](https://argo-cd.readthedocs.io/en/latest/user-guide/application-set/). You can have ArgoCD automatically discover and deploy any chart in the `workloads/` directory based on path patterns.

#### ArgoCD Application

For a single app, a standalone Application manifest works fine:

```yaml
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: openclaw
  namespace: argocd
spec:
  project: default
  source:
    repoURL: https://github.com/your-org/your-gitops-repo.git
    targetRevision: HEAD
    path: workloads/my-cluster/openclaw
  destination:
    server: https://kubernetes.default.svc
    namespace: openclaw
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
    syncOptions:
      - CreateNamespace=true
```

With `automated` sync enabled, ArgoCD continuously reconciles your deployment against the Git repository. Any drift gets corrected automatically. For more on ArgoCD with Helm charts, see their [Helm documentation](https://argo-cd.readthedocs.io/en/stable/user-guide/helm/).

### Secrets Management

OpenClaw needs API keys and tokens to function. How you manage these depends on your setup.

If you run HashiCorp Vault (which I do), the [Vault Secrets Operator](https://developer.hashicorp.com/vault/docs/platform/k8s/vso) handles syncing secrets to Kubernetes. Store your credentials in Vault at a path like `secret/openclaw/env`, then create a VaultStaticSecret. In the umbrella chart pattern, I keep these manifests in a `crds/` directory alongside the chart. ArgoCD will apply them before the Helm release:

```
openclaw/
├── Chart.yaml
├── values.yaml
└── crds/
    └── vault-secret.yaml
```

The manifest itself:

```yaml
apiVersion: secrets.hashicorp.com/v1beta1
kind: VaultStaticSecret
metadata:
  name: openclaw-env-secret
  namespace: openclaw
spec:
  vaultAuthRef: default
  mount: secret
  path: my-cluster/openclaw/env
  type: kv-v2
  destination:
    name: openclaw-env-secret
    create: true
```

Reference it in your Helm values:

```yaml
openclaw:
  app-template:
    controllers:
      main:
        containers:
          main:
            envFrom:
              - secretRef:
                  name: openclaw-env-secret
```

If you're not running Vault, a native Kubernetes Secret works. You can put it in the same `crds/` directory:

```yaml
apiVersion: v1
kind: Secret
metadata:
  name: openclaw-env-secret
  namespace: openclaw
type: Opaque
stringData:
  ANTHROPIC_API_KEY: "your-api-key-here"
  GATEWAY_TOKEN: "your-gateway-token-here"
```

Plain Kubernetes Secrets are base64-encoded, not encrypted at rest unless you've configured encryption.

### Networking and Access

OpenClaw needs to be reachable for its web UI and potentially for webhook integrations with messaging platforms.

For external access, I recommend [Cloudflare Tunnel](https://github.com/cloudflare/helm-charts/tree/main/charts/cloudflare-tunnel). The cloudflared daemon runs inside your cluster as a Deployment, and no inbound ports need to be opened on your firewall.

For homelab use where you don't need external access, keep OpenClaw internal. Access it via your local network or VPN. Don't expose services unnecessarily.

If you're exposing services within your cluster, [Gateway API](https://gateway-api.sigs.k8s.io/) is the way forward. [Retirement of ingress-nginx](https://kubernetes.io/blog/2025/11/11/ingress-nginx-retirement/) announced earlier last year, now's a good time to migrate to Gateway API. Here's a minimal HTTPRoute example:

```yaml
apiVersion: gateway.networking.k8s.io/v1
kind: HTTPRoute
metadata:
  name: openclaw
  namespace: openclaw
spec:
  parentRefs:
    - name: main-gateway
      namespace: gateway-system
  hostnames:
    - "openclaw.example.internal"
  rules:
    - matches:
        - path:
            type: PathPrefix
            value: /
      backendRefs:
        - name: openclaw
          port: 18789
```

For TLS termination and DNS automation (using tools like [cert-manager](https://cert-manager.io/) and [external-dns](https://github.com/kubernetes-sigs/external-dns)), that's a topic that deserves its own post. For now, just know the Helm chart exposes the service on port 18789 and you can wire it up however fits your setup.

### Post-Installation: Device Pairing

Once the pod is running, you need to pair your device with OpenClaw.

**1. Access the Web UI** at `https://openclaw.example.internal/`

**2. Enter Gateway Token** in Settings. If you're using Vault, this is the value stored at your configured path (e.g., `secret/my-cluster/openclaw/env`).

**3. Click "Connect"** to initiate a device pairing request. The request needs to be approved from within the pod.

**4. Approve the Device:**

```bash
# List pending devices
kubectl exec -n openclaw deployment/openclaw \
  --context my-cluster \
  -- node dist/index.js devices list

# Approve the device
kubectl exec -n openclaw deployment/openclaw \
  --context my-cluster \
  -- node dist/index.js devices approve <REQUEST_ID>
```

**5. Reconnect in the UI** and you should now have an active session.

Congrats, now you have a functional OpenClaw deployment in your Kubernetes setup.
